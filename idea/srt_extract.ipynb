{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d11dcd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_core.documents import Document\n",
    "from qdrant_client.http.models import PointStruct, VectorParams, Distance\n",
    "import re\n",
    "from pprint import pprint\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "QDRANT_COLLECTION = os.getenv(\"QDRANT_COLLECTION\", \"srt_subtitles\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1727434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'index': 1, 'start': '00:02:08,080', 'end': '00:02:12,240', 'movie_name': 'Shawshank Redemption', 'text': '...the confrontation you had with your wife the night she was murdered.'}, {'index': 2, 'start': '00:02:16,720', 'end': '00:02:18,320', 'movie_name': 'Shawshank Redemption', 'text': 'It was very bitter.'}, {'index': 3, 'start': '00:02:18,640', 'end': '00:02:22,760', 'movie_name': 'Shawshank Redemption', 'text': 'She said she was glad I knew, that she hated all the sneaking around.'}, {'index': 4, 'start': '00:02:24,280', 'end': '00:02:27,600', 'movie_name': 'Shawshank Redemption', 'text': 'And she said that she wanted a divorce in Reno.'}, {'index': 5, 'start': '00:02:27,840', 'end': '00:02:31,360', 'movie_name': 'Shawshank Redemption', 'text': '-What was your response? -I told her I would not grant one.'}, {'index': 6, 'start': '00:02:31,560', 'end': '00:02:34,600', 'movie_name': 'Shawshank Redemption', 'text': '\"I\\'ll see you in hell before I see you in Reno.\"'}, {'index': 7, 'start': '00:02:34,760', 'end': '00:02:38,000', 'movie_name': 'Shawshank Redemption', 'text': 'Those were your words, according to your neighbors.'}, {'index': 8, 'start': '00:02:39,000', 'end': '00:02:40,560', 'movie_name': 'Shawshank Redemption', 'text': 'If they say so.'}, {'index': 9, 'start': '00:02:41,080', 'end': '00:02:43,480', 'movie_name': 'Shawshank Redemption', 'text': \"I really don't remember. I was upset.\"}]\n"
     ]
    }
   ],
   "source": [
    "# Function to parse .srt file\n",
    "def parse_srt(file_path: str, movie_name: str, idx:int=0) -> List[Dict[str, str]]:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    pattern = re.compile(r'(\\d+)\\s+(\\d{2}:\\d{2}:\\d{2},\\d{3}) --> (\\d{2}:\\d{2}:\\d{2},\\d{3})\\s+(.+?)(?=\\n\\d+\\n|\\Z)', re.DOTALL)\n",
    "    matches = pattern.findall(content)\n",
    "    subtitles = []\n",
    "    for _, start, end, text in matches:\n",
    "        subtitles.append({\n",
    "            \"index\": int(idx),\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"movie_name\": movie_name,\n",
    "            \"text\": text.replace('\\n', ' ').strip()\n",
    "        })\n",
    "        idx += 1\n",
    "    return subtitles\n",
    "\n",
    "\n",
    "SRT_PATH = \"/Users/enkhbat_1/projects/ai-video-ge/movie-reels/srt_files/\"\n",
    "raw_srt_file = parse_srt(f\"{SRT_PATH}Shawshank_Redemption_1.srt\",movie_name=\"Shawshank Redemption\")\n",
    "print(raw_srt_file[1:10])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70adb680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'duration_minutes': 0.625,\n",
      " 'duration_seconds': 37.48,\n",
      " 'end': '00:02:43,480',\n",
      " 'index': 0,\n",
      " 'movie_name': 'Shawshank Redemption',\n",
      " 'original_count': 10,\n",
      " 'start': '00:02:06,000',\n",
      " 'text': 'Mr. Dufresne, describe... ...the confrontation you had with your '\n",
      "         'wife the night she was murdered. It was very bitter. She said she '\n",
      "         'was glad I knew, that she hated all the sneaking around. And she '\n",
      "         'said that she wanted a divorce in Reno. -What was your response? -I '\n",
      "         'told her I would not grant one. \"I\\'ll see you in hell before I see '\n",
      "         'you in Reno.\" Those were your words, according to your neighbors. If '\n",
      "         \"they say so. I really don't remember. I was upset.\"}\n",
      "{'end': '00:02:07,880',\n",
      " 'index': 0,\n",
      " 'movie_name': 'Shawshank Redemption',\n",
      " 'start': '00:02:06,000',\n",
      " 'text': 'Mr. Dufresne, describe...'}\n"
     ]
    }
   ],
   "source": [
    "def concatenate_subtitles_by_chunks(subtitles, chunk_size=3):\n",
    "    \"\"\"\n",
    "    Concatenate subtitles into chunks of specified size\n",
    "    \n",
    "    Args:\n",
    "        subtitles: List of subtitle dictionaries\n",
    "        chunk_size: Number of subtitles to combine in each chunk\n",
    "    \n",
    "    Returns:\n",
    "        List of concatenated subtitle chunks\n",
    "    \"\"\"\n",
    "    def time_to_seconds(time_str):\n",
    "        \"\"\"Convert 'HH:MM:SS,mmm' format to seconds\"\"\"\n",
    "        time_part, ms = time_str.split(',')\n",
    "        h, m, s = map(int, time_part.split(':'))\n",
    "        return h * 3600 + m * 60 + s + int(ms) / 1000\n",
    "    \n",
    "    def seconds_to_time(seconds):\n",
    "        \"\"\"Convert seconds back to 'HH:MM:SS,mmm' format\"\"\"\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        secs = int(seconds % 60)\n",
    "        ms = int((seconds % 1) * 1000)\n",
    "        return f\"{hours:02d}:{minutes:02d}:{secs:02d},{ms:03d}\"\n",
    "    \n",
    "    concatenated_subtitles = []\n",
    "    \n",
    "    # Process subtitles in chunks\n",
    "    for i in range(0, len(subtitles), chunk_size):\n",
    "        chunk = subtitles[i:i + chunk_size]\n",
    "        \n",
    "        if not chunk:\n",
    "            continue\n",
    "            \n",
    "        # Combine text from all subtitles in chunk\n",
    "        combined_text = ' '.join(subtitle['text'] for subtitle in chunk)\n",
    "        \n",
    "        # Get start and end times\n",
    "        start_time = chunk[0]['start']\n",
    "        end_time = chunk[-1]['end']\n",
    "        \n",
    "        # Calculate duration\n",
    "        start_seconds = time_to_seconds(start_time)\n",
    "        end_seconds = time_to_seconds(end_time)\n",
    "        total_duration = end_seconds - start_seconds\n",
    "        \n",
    "        # Create combined subtitle entry\n",
    "        combined_subtitle = {\n",
    "            'index': len(concatenated_subtitles),\n",
    "            'start': start_time,\n",
    "            'end': end_time,\n",
    "            'movie_name': chunk[0]['movie_name'],\n",
    "            'text': combined_text,\n",
    "            'duration_seconds': round(total_duration, 3),\n",
    "            'duration_minutes': round(total_duration / 60, 3),\n",
    "            'original_count': len(chunk)\n",
    "        }\n",
    "        \n",
    "        concatenated_subtitles.append(combined_subtitle)\n",
    "    \n",
    "    return concatenated_subtitles\n",
    "\n",
    " # Combine subtitles into chunks of 10\n",
    "combined_srt = concatenate_subtitles_by_chunks(raw_srt_file, chunk_size=10)\n",
    "pprint(combined_srt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffc10dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'index': 0, 'start': '00:02:06,000', 'end': '00:02:43,480', 'movie_name': 'Shawshank Redemption', 'text': 'Mr. Dufresne, describe... ...the confrontation you had with your wife the night she was murdered. It was very bitter. She said she was glad I knew, that she hated all the sneaking around. And she said that she wanted a divorce in Reno. -What was your response? -I told her I would not grant one. \"I\\'ll see you in hell before I see you in Reno.\" Those were your words, according to your neighbors. If they say so. I really don\\'t remember. I was upset.', 'duration_seconds': 37.48, 'duration_minutes': 0.625, 'original_count': 10, 'start_index': 0}, page_content='Mr. Dufresne, describe... ...the confrontation you had with your wife the night she was murdered. It'), Document(metadata={'index': 0, 'start': '00:02:06,000', 'end': '00:02:43,480', 'movie_name': 'Shawshank Redemption', 'text': 'Mr. Dufresne, describe... ...the confrontation you had with your wife the night she was murdered. It was very bitter. She said she was glad I knew, that she hated all the sneaking around. And she said that she wanted a divorce in Reno. -What was your response? -I told her I would not grant one. \"I\\'ll see you in hell before I see you in Reno.\" Those were your words, according to your neighbors. If they say so. I really don\\'t remember. I was upset.', 'duration_seconds': 37.48, 'duration_minutes': 0.625, 'original_count': 10, 'start_index': 98}, page_content='It was very bitter. She said she was glad I knew, that she hated all the sneaking around. And she'), Document(metadata={'index': 0, 'start': '00:02:06,000', 'end': '00:02:43,480', 'movie_name': 'Shawshank Redemption', 'text': 'Mr. Dufresne, describe... ...the confrontation you had with your wife the night she was murdered. It was very bitter. She said she was glad I knew, that she hated all the sneaking around. And she said that she wanted a divorce in Reno. -What was your response? -I told her I would not grant one. \"I\\'ll see you in hell before I see you in Reno.\" Those were your words, according to your neighbors. If they say so. I really don\\'t remember. I was upset.', 'duration_seconds': 37.48, 'duration_minutes': 0.625, 'original_count': 10, 'start_index': 188}, page_content='And she said that she wanted a divorce in Reno. -What was your response? -I told her I would not')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def prepare_documents(raw_srt_file: List[dict]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Convert raw SRT file data to LangChain Document objects.\n",
    "    \n",
    "    Args:\n",
    "        raw_srt_file (list): List of dictionaries containing subtitle data.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of LangChain Document objects.\n",
    "    \"\"\"\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=100, chunk_overlap=10, add_start_index=True\n",
    "    )\n",
    "    return text_splitter.split_documents([\n",
    "        Document(page_content=sub[\"text\"],metadata=sub)\n",
    "        for sub in raw_srt_file\n",
    "    ])\n",
    "\n",
    "# Convert raw_srt_file to LangChain Document objects\n",
    "all_splits = prepare_documents(combined_srt)\n",
    "\n",
    "len(all_splits)  # Total number of splits\n",
    "\n",
    "print(all_splits[0:3])  # Print the content of the first split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29a1b380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enkhbat_1/projects/ai-video-ge/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"Qwen/Qwen3-Embedding-0.6B\",\n",
    "                                   cache_folder= \"/Users/enkhbat_1/projects/ai-video-ge/cache-models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7eceb4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "from qdrant_client.models import NamedSparseVector, SparseVector\n",
    "\n",
    "def vectorize_documents(documents: List[Document], embedding_model:HuggingFaceEmbeddings,labels:List[str]) -> List[PointStruct]:\n",
    "    \"\"\"\n",
    "    Convert LangChain Document objects to Qdrant PointStructs with embeddings.\n",
    "\n",
    "    Args:\n",
    "        documents (list): List of LangChain Document objects.\n",
    "        embedding_model: Embedding model to generate vector embeddings.\n",
    "        labels (list): List of labels for the documents.\n",
    "\n",
    "    Returns:\n",
    "        list: List of PointStructs with embeddings.\n",
    "    \"\"\"\n",
    "    label_embeddings = {label: embedding_model.embed_query(label) for label in labels}\n",
    "    points = []\n",
    "    for doc in documents:\n",
    "        dense_vector = embedding_model.embed_query(doc.page_content)\n",
    "        sparse_vector = {\n",
    "            label: float(cosine_similarity(np.asarray(dense_vector).reshape(1, -1), np.asarray(label_embeddings[label]).reshape(1, -1))[0, 0]) for label in labels\n",
    "        }\n",
    "        \n",
    "        points.append(\n",
    "            {\n",
    "                \"id\": doc.metadata[\"index\"],\n",
    "                \"vector\": dense_vector,\n",
    "                \"sparse_vector\": sparse_vector,\n",
    "                \"payload\": {\n",
    "                    \"start\": doc.metadata[\"start\"],\n",
    "                    \"end\": doc.metadata[\"end\"],\n",
    "                    \"movie_name\": doc.metadata[\"movie_name\"],\n",
    "                    \"text\": doc.page_content\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    return points\n",
    "\n",
    "vectorized_points = vectorize_documents(all_splits, embeddings, labels=[\"action\", \"motivational\", \"comedy\",\"scary\",\"si-fi\",\"romantic\",\"drama\",\"thriller\"])\n",
    "\n",
    "# print(embeddings.embed_query(\"This is a test sentence.\").reshape(1,-1))  # Example embedding\n",
    "# print(vectorized_points[0])  # Print the first vectorized point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0af2bcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': '00:08:05,440', 'end': '00:08:30,600', 'movie_name': 'Shawshank Redemption', 'text': 'Damn near anything within reason.'}\n"
     ]
    }
   ],
   "source": [
    "filtered_points = list(filter(lambda x: x['sparse_vector']['comedy']>0.5, vectorized_points)) \n",
    "print(filtered_points[0]['payload']) # Filter points with sparse_vector > 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cec1b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.embed_query(all_splits[2].page_content))  # Example embedding for the first split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da3dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client = QdrantClient(\n",
    "    url=QDRANT_URL,  # Use QDRANT_URL from environment variables\n",
    "    api_key=QDRANT_API_KEY\n",
    ")\n",
    "\n",
    "\n",
    "# client.delete_collection(QDRANT_COLLECTION)  # Delete the collection if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c767168",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'sparse_embedding' cannot be None when retrieval mode is 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_qdrant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetrievalMode\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Insert the documents into Qdrant\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m vector_store = \u001b[43mQdrantVectorStore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mall_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mQDRANT_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mQDRANT_API_KEY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msrt_subtitles\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretrieval_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRetrievalMode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSPARSE\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/ai-video-ge/.venv/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:848\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    846\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/ai-video-ge/.venv/lib/python3.11/site-packages/langchain_qdrant/qdrant.py:343\u001b[39m, in \u001b[36mQdrantVectorStore.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, location, url, port, grpc_port, prefer_grpc, https, api_key, prefix, timeout, host, path, distance, content_payload_key, metadata_payload_key, vector_name, retrieval_mode, sparse_embedding, sparse_vector_name, collection_create_options, vector_params, sparse_vector_params, batch_size, force_recreate, validate_embeddings, validate_collection_config, **kwargs)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Construct an instance of `QdrantVectorStore` from a list of texts.\u001b[39;00m\n\u001b[32m    312\u001b[39m \n\u001b[32m    313\u001b[39m \u001b[33;03mThis is a user-friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m \u001b[33;03m    qdrant = Qdrant.from_texts(texts, embeddings, url=\"http://localhost:6333\")\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    328\u001b[39m client_options = {\n\u001b[32m    329\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlocation\u001b[39m\u001b[33m\"\u001b[39m: location,\n\u001b[32m    330\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33murl\u001b[39m\u001b[33m\"\u001b[39m: url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    340\u001b[39m     **kwargs,\n\u001b[32m    341\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m qdrant = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconstruct_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretrieval_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43msparse_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent_payload_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata_payload_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvector_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43msparse_vector_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_recreate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_create_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvector_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43msparse_vector_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate_collection_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    361\u001b[39m qdrant.add_texts(texts, metadatas, ids, batch_size)\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m qdrant\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/ai-video-ge/.venv/lib/python3.11/site-packages/langchain_qdrant/qdrant.py:806\u001b[39m, in \u001b[36mQdrantVectorStore.construct_instance\u001b[39m\u001b[34m(cls, embedding, retrieval_mode, sparse_embedding, client_options, collection_name, distance, content_payload_key, metadata_payload_key, vector_name, sparse_vector_name, force_recreate, collection_create_options, vector_params, sparse_vector_params, validate_embeddings, validate_collection_config)\u001b[39m\n\u001b[32m    785\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconstruct_instance\u001b[39m(\n\u001b[32m    787\u001b[39m     \u001b[38;5;28mcls\u001b[39m: Type[QdrantVectorStore],\n\u001b[32m   (...)\u001b[39m\u001b[32m    803\u001b[39m     validate_collection_config: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    804\u001b[39m ) -> QdrantVectorStore:\n\u001b[32m    805\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m validate_embeddings:\n\u001b[32m--> \u001b[39m\u001b[32m806\u001b[39m         \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretrieval_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_embedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    807\u001b[39m     collection_name = collection_name \u001b[38;5;129;01mor\u001b[39;00m uuid.uuid4().hex\n\u001b[32m    808\u001b[39m     client = QdrantClient(**client_options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/ai-video-ge/.venv/lib/python3.11/site-packages/langchain_qdrant/qdrant.py:1168\u001b[39m, in \u001b[36mQdrantVectorStore._validate_embeddings\u001b[39m\u001b[34m(cls, retrieval_mode, embedding, sparse_embedding)\u001b[39m\n\u001b[32m   1163\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1164\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m\u001b[33m cannot be None when retrieval mode is \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdense\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1165\u001b[39m     )\n\u001b[32m   1167\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m retrieval_mode == RetrievalMode.SPARSE \u001b[38;5;129;01mand\u001b[39;00m sparse_embedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1169\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33msparse_embedding\u001b[39m\u001b[33m'\u001b[39m\u001b[33m cannot be None when retrieval mode is \u001b[39m\u001b[33m'\u001b[39m\u001b[33msparse\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1170\u001b[39m     )\n\u001b[32m   1172\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m retrieval_mode == RetrievalMode.HYBRID \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1173\u001b[39m     [embedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, sparse_embedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m   1174\u001b[39m ):\n\u001b[32m   1175\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1176\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mBoth \u001b[39m\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33msparse_embedding\u001b[39m\u001b[33m'\u001b[39m\u001b[33m cannot be None \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1177\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwhen retrieval mode is \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhybrid\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1178\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: 'sparse_embedding' cannot be None when retrieval mode is 'sparse'"
     ]
    }
   ],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_qdrant import RetrievalMode\n",
    "\n",
    "# Insert the documents into Qdrant\n",
    "vector_store = QdrantVectorStore.from_documents(\n",
    "    all_splits,embeddings,\n",
    "    url = QDRANT_URL,\n",
    "    api_key = QDRANT_API_KEY,\n",
    "    collection_name=\"srt_subtitles\",\n",
    "    retrieval_mode=RetrievalMode.DENSE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8563c640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ScoredPoint(id='e779bacb-cb85-4694-81c5-e3a156769110', version=20, score=0.6050934, payload={'page_content': 'Waste of money, if you ask me.', 'metadata': {'index': 340, 'start': '00:26:43,600', 'end': '00:26:45,560', 'movie_name': 'Shawshank Redemption', 'start_index': 0}}, vector=None, shard_key=None, order_value=None),\n",
      " ScoredPoint(id='cc523f6f-9089-4418-8880-3c9b8d17152b', version=5, score=0.6050934, payload={'page_content': 'Waste of money, if you ask me.', 'metadata': {'index': 340, 'start': '00:26:43,600', 'end': '00:26:45,560', 'movie_name': 'Shawshank Redemption', 'start_index': 0}}, vector=None, shard_key=None, order_value=None),\n",
      " ScoredPoint(id='c9ee01a2-0442-46e8-ae51-fbb6706394f5', version=6, score=0.6033416, payload={'page_content': 'A million bucks?', 'metadata': {'index': 420, 'start': '00:33:07,120', 'end': '00:33:08,920', 'movie_name': 'Shawshank Redemption', 'start_index': 0}}, vector=None, shard_key=None, order_value=None)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from qdrant_client import models\n",
    "\n",
    "# Perform a similarity search\n",
    "retrieve = client.query_points(\n",
    "    collection_name=\"srt_subtitles\",\n",
    "    query=embeddings.embed_query(\"Earn money\"),\n",
    "    limit=3,\n",
    "     search_params=models.SearchParams(hnsw_ef=128, exact=False), # Explore 128 values before returning results\n",
    ")\n",
    "pprint(retrieve.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f6495a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'index': 340, 'start': '00:26:43,600', 'end': '00:26:45,560', 'movie_name': 'Shawshank Redemption', 'start_index': 0, '_id': 'e779bacb-cb85-4694-81c5-e3a156769110', '_collection_name': 'srt_subtitles'}, page_content='Waste of money, if you ask me.'),\n",
      " Document(metadata={'index': 340, 'start': '00:26:43,600', 'end': '00:26:45,560', 'movie_name': 'Shawshank Redemption', 'start_index': 0, '_id': 'cc523f6f-9089-4418-8880-3c9b8d17152b', '_collection_name': 'srt_subtitles'}, page_content='Waste of money, if you ask me.'),\n",
      " Document(metadata={'index': 420, 'start': '00:33:07,120', 'end': '00:33:08,920', 'movie_name': 'Shawshank Redemption', 'start_index': 0, '_id': 'c9ee01a2-0442-46e8-ae51-fbb6706394f5', '_collection_name': 'srt_subtitles'}, page_content='A million bucks?')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform a similarity search\n",
    "\n",
    "query = \"Earn money\"\n",
    "found_docs = vector_store.similarity_search(query, k=3)\n",
    "pprint(found_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287c5466",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chat with Gemini model\n",
    "import os\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Use Gemini instead of Gemma for system prompt support\n",
    "model = init_chat_model(model=\"gemini-1.5-flash\",\n",
    "                         model_provider=\"google_genai\", \n",
    "                         api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# For Gemma models, combine system instruction with human message\n",
    "messages = [\n",
    "    HumanMessage(\"Translate the following from English into Italian: hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages).content\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
